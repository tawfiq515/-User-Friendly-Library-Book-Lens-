{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e62d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, time, math, json, sqlite3, requests\n",
    "from itertools import product\n",
    "from typing import List, Tuple\n",
    "\n",
    "API_URL   = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "API_KEY   = None  # ضيفي مفتاحك هون لو عندك (مثلاً \"AIza...\") أو خليه None\n",
    "PER_PAGE  = 40\n",
    "PER_QUERY_CAP = 1000\n",
    "SLEEP_BASE = 0.25\n",
    "\n",
    "# 📌 مسار قاعدة البيانات (يتسيف بالفولدر المطلوب)\n",
    "DB_PATH = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\books_crawl.sqlite\"\n",
    "TABLE_BOOKS = \"books\"\n",
    "TABLE_STATE = \"crawl_state\"\n",
    "\n",
    "# --------- 1) توليد الباكتات ----------\n",
    "letters = [chr(c) for c in range(ord('a'), ord('z')+1)]\n",
    "digits  = [str(d) for d in range(10)]\n",
    "author_prefixes = letters + digits   # 36 بادئة\n",
    "title_prefixes  = letters            # 26 بادئة\n",
    "\n",
    "def generate_buckets() -> List[Tuple[str, str, str]]:\n",
    "    \"\"\"\n",
    "    كل باكت عبارة عن (q_string, bucket_key, hint)\n",
    "    \"\"\"\n",
    "    buckets = []\n",
    "\n",
    "    # الباكتات الأساسية (حرف واحد للعنوان × حرف/رقم للمؤلف)\n",
    "    for t, a in product(title_prefixes, author_prefixes):\n",
    "        q = f'intitle:{t} inauthor:{a}'\n",
    "        key = f'intitle_{t}__inauthor_{a}'\n",
    "        buckets.append((q, key, f\"title starts {t}, author starts {a}\"))\n",
    "\n",
    "    # ✅ ثنائيات العنوان (aa, ab, ..., zz)\n",
    "    for t2 in (f\"{x}{y}\" for x,y in product(letters, letters)):\n",
    "        q = f'intitle:{t2}'\n",
    "        key = f'intitle_{t2}'\n",
    "        buckets.append((q, key, f\"title starts {t2}\"))\n",
    "\n",
    "    return buckets\n",
    "\n",
    "# --------- 2) قاعدة البيانات ----------\n",
    "def init_db():\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TABLE_BOOKS} (\n",
    "        id TEXT PRIMARY KEY,\n",
    "        title TEXT,\n",
    "        authors TEXT,\n",
    "        publishedDate TEXT,\n",
    "        industryIds TEXT,\n",
    "        raw JSON\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TABLE_STATE} (\n",
    "        bucket_key TEXT PRIMARY KEY,\n",
    "        q TEXT NOT NULL,\n",
    "        next_start INTEGER NOT NULL DEFAULT 0,\n",
    "        done INTEGER NOT NULL DEFAULT 0,\n",
    "        total_reported INTEGER\n",
    "    );\n",
    "    \"\"\")\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "def save_state(bucket_key, q, next_start, done, total_reported=None):\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(f\"\"\"\n",
    "    INSERT INTO {TABLE_STATE} (bucket_key, q, next_start, done, total_reported)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ON CONFLICT(bucket_key)\n",
    "    DO UPDATE SET next_start=excluded.next_start, done=excluded.done,\n",
    "                  total_reported=COALESCE(excluded.total_reported, {TABLE_STATE}.total_reported);\n",
    "    \"\"\", (bucket_key, q, next_start, done, total_reported))\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "def load_state(bucket_key):\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(f\"SELECT q, next_start, done, total_reported FROM {TABLE_STATE} WHERE bucket_key=?;\", (bucket_key,))\n",
    "    row = cur.fetchone()\n",
    "    con.close()\n",
    "    if row:\n",
    "        return {\"q\": row[0], \"next_start\": row[1], \"done\": row[2], \"total_reported\": row[3]}\n",
    "    return None\n",
    "\n",
    "def insert_books(items):\n",
    "    if not items:\n",
    "        return 0\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    cur = con.cursor()\n",
    "    count = 0\n",
    "    for it in items:\n",
    "        bid = it.get(\"id\")\n",
    "        if not bid:\n",
    "            continue\n",
    "        vol = it.get(\"volumeInfo\", {})\n",
    "        title = vol.get(\"title\")\n",
    "        authors = \", \".join(vol.get(\"authors\", [])) if vol.get(\"authors\") else None\n",
    "        pubdate = vol.get(\"publishedDate\")\n",
    "        inds = vol.get(\"industryIdentifiers\", [])\n",
    "        inds_str = json.dumps(inds, ensure_ascii=False)\n",
    "        raw = json.dumps(it, ensure_ascii=False)\n",
    "        try:\n",
    "            cur.execute(f\"\"\"\n",
    "            INSERT OR IGNORE INTO {TABLE_BOOKS}(id, title, authors, publishedDate, industryIds, raw)\n",
    "            VALUES (?, ?, ?, ?, ?, ?);\n",
    "            \"\"\", (bid, title, authors, pubdate, inds_str, raw))\n",
    "            count += cur.rowcount\n",
    "        except sqlite3.Error:\n",
    "            pass\n",
    "    con.commit()\n",
    "    con.close()\n",
    "    return count\n",
    "\n",
    "# --------- 3) طلب API مع Backoff ----------\n",
    "def get_page(q, start_index=0, per_page=PER_PAGE):\n",
    "    params = {\"q\": q, \"maxResults\": per_page, \"startIndex\": start_index}\n",
    "    if API_KEY:\n",
    "        params[\"key\"] = API_KEY\n",
    "\n",
    "    backoff = SLEEP_BASE\n",
    "    for attempt in range(6):\n",
    "        r = requests.get(API_URL, params=params, timeout=30)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()\n",
    "        elif r.status_code in (429, 403, 500, 503):\n",
    "            time.sleep(backoff)\n",
    "            backoff = min(backoff * 2, 8.0)\n",
    "        else:\n",
    "            raise requests.HTTPError(f\"{r.status_code} {r.reason} — {r.url}\")\n",
    "    r.raise_for_status()\n",
    "\n",
    "# --------- 4) زحف باكت واحد ----------\n",
    "def crawl_bucket(q, bucket_key):\n",
    "    st = load_state(bucket_key)\n",
    "    start = 0\n",
    "    total_reported = None\n",
    "\n",
    "    if st:\n",
    "        if st[\"done\"]:\n",
    "            return 0, 0, st.get(\"total_reported\")\n",
    "        start = st[\"next_start\"] or 0\n",
    "        total_reported = st.get(\"total_reported\")\n",
    "\n",
    "    if start == 0:\n",
    "        first = get_page(q, start_index=0)\n",
    "        total_reported = first.get(\"totalItems\", 0)\n",
    "        items = first.get(\"items\", []) or []\n",
    "        insert_books(items)\n",
    "        start = len(items)\n",
    "        save_state(bucket_key, q, start, 0, total_reported)\n",
    "        time.sleep(SLEEP_BASE)\n",
    "\n",
    "    inserted_total = 0\n",
    "    while start < min(total_reported or PER_QUERY_CAP, PER_QUERY_CAP):\n",
    "        try:\n",
    "            data = get_page(q, start_index=start)\n",
    "        except requests.HTTPError as e:\n",
    "            print(f\"[{bucket_key}] HTTPError at start={start}: {e}\")\n",
    "            break\n",
    "        items = data.get(\"items\", []) or []\n",
    "        if not items:\n",
    "            break\n",
    "        inserted = insert_books(items)\n",
    "        inserted_total += inserted\n",
    "        start += len(items)\n",
    "        save_state(bucket_key, q, start, 0, total_reported)\n",
    "        time.sleep(SLEEP_BASE)\n",
    "\n",
    "    save_state(bucket_key, q, start, 1, total_reported)\n",
    "    return inserted_total, start, total_reported\n",
    "\n",
    "# --------- 5) زحف الكل ----------\n",
    "def crawl_all(target_count=1_000_000):\n",
    "    init_db()\n",
    "    buckets = generate_buckets()\n",
    "    total_before = count_books()\n",
    "    print(f\"Existing in DB before: {total_before}\")\n",
    "\n",
    "    for i, (q, key, hint) in enumerate(buckets, 1):\n",
    "        st = load_state(key)\n",
    "        if st and st[\"done\"]:\n",
    "            continue\n",
    "        print(f\"[{i}/{len(buckets)}] Bucket: {key} — {hint}\")\n",
    "        inserted, fetched, total_reported = crawl_bucket(q, key)\n",
    "        current = count_books()\n",
    "        print(f\"  inserted:{inserted}  fetched≈{fetched}  total_reported={total_reported}  DB now:{current}\")\n",
    "        if current >= target_count:\n",
    "            print(\"Reached target. Stopping.\")\n",
    "            break\n",
    "\n",
    "    print(f\"Final DB count: {count_books()}\")\n",
    "\n",
    "def count_books():\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {TABLE_BOOKS};\")\n",
    "    c = cur.fetchone()[0]\n",
    "    con.close()\n",
    "    return c\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crawl_all(target_count=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bfbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\books_crawl.sqlite\"\n",
    "TABLE_BOOKS = \"books\"\n",
    "\n",
    "# اتصال بالقاعدة\n",
    "con = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# جلب أول صف فقط لمعرفة الأعمدة\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {TABLE_BOOKS} LIMIT 1\", con)\n",
    "con.close()\n",
    "\n",
    "# عرض أسماء الأعمدة وعددها\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Number of columns:\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f941d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\books_crawl.sqlite\"\n",
    "TABLE_BOOKS = \"books\"\n",
    "\n",
    "# اتصال بالقاعدة\n",
    "con = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# قراءة الجدول\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {TABLE_BOOKS}\", con)\n",
    "con.close()\n",
    "\n",
    "# عدد الصفوف (الريكورد)\n",
    "total_records = len(df)\n",
    "print(f\"Total records in DB: {total_records}\\n\")\n",
    "\n",
    "# حساب عدد القيم الفارغة لكل عمود\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "# عرض النتيجة\n",
    "for col, nulls in null_counts.items():\n",
    "    print(f\"{col}: {nulls} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\books_crawl.sqlite\"\n",
    "TABLE_BOOKS = \"books\"\n",
    "\n",
    "# اتصال بالقاعدة\n",
    "con = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# قراءة الجدول\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {TABLE_BOOKS}\", con)\n",
    "con.close()\n",
    "\n",
    "# طباعة أول 5 صفوف لكل عمود\n",
    "for col in df.columns:\n",
    "    print(f\"--- Column: {col} ---\")\n",
    "    print(df[col].head(5))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc60f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "db_path = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\books_crawl.sqlite\"\n",
    "new_db = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\new_books_crawl.sqlite\"\n",
    "\n",
    "shutil.copyfile(db_path, new_db)\n",
    "print(\"Copy created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f48b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# مسار الداتا بيس الجديدة\n",
    "new_db = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\new_books_crawl.sqlite\"\n",
    "TABLE_BOOKS = \"books\"\n",
    "\n",
    "# فتح الاتصال بالداتا بيس\n",
    "con = sqlite3.connect(new_db)\n",
    "\n",
    "# قراءة الجدول\n",
    "try:\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM {TABLE_BOOKS}\", con)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    con.close()\n",
    "    raise\n",
    "\n",
    "con.close()\n",
    "\n",
    "# عدد الصفوف (الريكورد)\n",
    "total_records = len(df)\n",
    "print(f\"Total records in DB: {total_records}\\n\")\n",
    "\n",
    "# حساب عدد القيم الفارغة لكل عمود\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "# عرض النتيجة\n",
    "for col, nulls in null_counts.items():\n",
    "    print(f\"{col}: {nulls} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# مسار الداتا بيس الجديدة\n",
    "new_db = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\new_books_crawl.sqlite\"\n",
    "TABLE_BOOKS = \"books\"\n",
    "\n",
    "# فتح الاتصال\n",
    "con = sqlite3.connect(new_db)\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {TABLE_BOOKS}\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97650c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# نعمل أعمدة جديدة من industryIds\n",
    "def extract_industry_ids(industry_json):\n",
    "    try:\n",
    "        data = json.loads(industry_json)\n",
    "        # نجمع كل identifiers بفاصلة\n",
    "        return ', '.join(item.get(\"identifier\", \"\") for item in data)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['industry_identifiers'] = df['industryIds'].apply(extract_industry_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcfe36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(raw_json):\n",
    "    try:\n",
    "        data = json.loads(raw_json)\n",
    "        volume_info = data.get(\"volumeInfo\", {})\n",
    "        sale_info = data.get(\"saleInfo\", {})\n",
    "        access_info = data.get(\"accessInfo\", {})\n",
    "\n",
    "        return pd.Series({\n",
    "            \"selfLink\": data.get(\"selfLink\"),\n",
    "            \"title\": volume_info.get(\"title\"),\n",
    "            \"authors\": ', '.join(volume_info.get(\"authors\", [])) if volume_info.get(\"authors\") else None,\n",
    "            \"publishedDate\": volume_info.get(\"publishedDate\"),\n",
    "            \"description\": volume_info.get(\"description\"),\n",
    "            \"reading_text\": volume_info.get(\"readingModes\", {}).get(\"text\"),\n",
    "            \"reading_image\": volume_info.get(\"readingModes\", {}).get(\"image\"),\n",
    "            \"pageCount\": volume_info.get(\"pageCount\"),\n",
    "            \"printType\": volume_info.get(\"printType\"),\n",
    "            \"categories\": ', '.join(volume_info.get(\"categories\", [])) if volume_info.get(\"categories\") else None,\n",
    "            \"thumbnail\": volume_info.get(\"imageLinks\", {}).get(\"thumbnail\"),\n",
    "            \"language\": volume_info.get(\"language\"),\n",
    "            \"infoLink\": volume_info.get(\"infoLink\"),\n",
    "            \"saleability\": sale_info.get(\"saleability\"),\n",
    "            \"isEbook\": sale_info.get(\"isEbook\"),\n",
    "            \"pdf_available\": access_info.get(\"pdf\", {}).get(\"isAvailable\")\n",
    "        })\n",
    "    \n",
    "    except:\n",
    "        return pd.Series([None]*17, index=[\n",
    "            \"selfLink\",\"title\",\"authors\",\"publishedDate\",\"description\",\n",
    "            \"reading_text\",\"reading_image\",\"pageCount\",\"printType\",\n",
    "            \"categories\",\"thumbnail\",\"language\",\"infoLink\",\"saleability\",\n",
    "            \"isEbook\",\"pdf_available\"\n",
    "        ])\n",
    "\n",
    "# نفك كل الفيتشرات من raw\n",
    "features_df = df['raw'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df, features_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70791525",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_final.columns[df_final.columns.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a257e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.loc[:, ~df_final.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeeebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(new_db)\n",
    "df_final.to_sql(TABLE_BOOKS, con, if_exists=\"replace\", index=False)\n",
    "con.close()\n",
    "print(\"Features extracted and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7cdc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "con = sqlite3.connect(new_db)\n",
    "df_check = pd.read_sql_query(f\"SELECT * FROM {TABLE_BOOKS}\", con)\n",
    "con.close()\n",
    "\n",
    "print(f\"Total records in new DB: {len(df_check)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_check.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_check.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc81a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# عدد الأعمدة في الداتا فريم\n",
    "num_columns = len(df_final.columns)\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c63ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حساب عدد القيم الفارغة لكل عمود\n",
    "null_counts = df_final.isnull().sum()\n",
    "\n",
    "# عرض النتيجة\n",
    "for col, nulls in null_counts.items():\n",
    "    print(f\"{col}: {nulls} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# نحذف العمودين من الداتا فريم\n",
    "df_final = df_final.drop(columns=['raw', 'industryIds'])\n",
    "\n",
    "# نكتب الداتا فريم المحدثة بالداتا بيس\n",
    "con = sqlite3.connect(new_db)  # الداتا بيس الجديد\n",
    "df_final.to_sql(TABLE_BOOKS, con, if_exists=\"replace\", index=False)\n",
    "con.close()\n",
    "\n",
    "print(\"raw و industryIds تم حذفهم والداتا بيس تم تحديثها بنجاح!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# عدد الأعمدة في الداتا فريم\n",
    "num_columns = len(df_final.columns)\n",
    "print(f\"Number of columns: {num_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حساب عدد القيم الفارغة لكل عمود\n",
    "null_counts = df_final.isnull().sum()\n",
    "\n",
    "# عرض النتيجة\n",
    "for col, nulls in null_counts.items():\n",
    "    print(f\"{col}: {nulls} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22562c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# فتح الداتا بيس الجديد\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "con = sqlite3.connect(new_db)\n",
    "df_sample = pd.read_sql_query(f\"SELECT * FROM {TABLE_BOOKS} LIMIT 5\", con)\n",
    "con.close()\n",
    "\n",
    "# عرض العينة\n",
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf314a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# عرض جميع التصنيفات الفريدة وعدد الكتب بكل تصنيف\n",
    "category_counts = df_final['categories'].value_counts(dropna=False)\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce5de2",
   "metadata": {},
   "source": [
    "\n",
    "# cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93658984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# مسار قاعدة البيانات\n",
    "new_db = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\new_books_crawl.sqlite\"\n",
    "TABLE_BOOKS = \"books\"\n",
    "\n",
    "# الاتصال\n",
    "con = sqlite3.connect(new_db)\n",
    "\n",
    "# قراءة البيانات\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {TABLE_BOOKS}\", con)\n",
    "\n",
    "print(\"قبل الحذف:\", len(df))\n",
    "\n",
    "# حذف الصفوف اللي فيها null بـ title أو authors\n",
    "df = df.dropna(subset=[\"title\", \"authors\"])\n",
    "\n",
    "print(\"بعد الحذف:\", len(df))\n",
    "\n",
    "# حفظ التغييرات في الداتا بيس\n",
    "df.to_sql(TABLE_BOOKS, con, if_exists=\"replace\", index=False)\n",
    "con.close()\n",
    "\n",
    "print(\"تم حذف الصفوف اللي فيها null بـ title أو authors وحفظ التغييرات.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# الاتصال بالداتا بيس\n",
    "new_db = r\"C:\\Users\\Rama Al Jada\\Desktop\\testbook\\new_books_crawl.sqlite\"\n",
    "TABLE_BOOKS = \"books\"\n",
    "\n",
    "con = sqlite3.connect(new_db)\n",
    "\n",
    "# قراءة الداتا\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {TABLE_BOOKS}\", con)\n",
    "\n",
    "# حذف الصفوف اللي فيها null بالـ title أو authors\n",
    "df = df.dropna(subset=[\"title\", \"authors\"])\n",
    "\n",
    "# نشوف nulls بعد التنظيف\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "print(\"عدد القيم الفارغة بعد التنظيف:\\n\")\n",
    "for col, nulls in null_counts.items():\n",
    "    print(f\"{col}: {nulls} null values\")\n",
    "\n",
    "# نرجع نخزن الداتا المنظفة مكان الجدول\n",
    "df.to_sql(TABLE_BOOKS, con, if_exists=\"replace\", index=False)\n",
    "\n",
    "con.close()\n",
    "print(\"\\nتم الحذف والتخزين بنجاح ✅\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
